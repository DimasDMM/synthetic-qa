{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic SQuAD dataset based on MKQA (Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to install some Spacy dictionaries:\n",
    "- `python -m spacy download en_core_web_sm`\n",
    "- `python -m spacy download es_core_news_sm`\n",
    "- `python -m spacy download ru_core_news_sm`\n",
    "- `python -m spacy download ja_core_news_sm`\n",
    "- `python -m spacy download xx_ent_wiki_sm`\n",
    "\n",
    "For Vietnamese, install this repo: https://github.com/trungtv/vi_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import mwparserfromhell\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import spacy\n",
    "import threading\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_NAME = 'bert-base-multilingual-cased'\n",
    "INPUT_FILE = '../data/mkqa/mkqa.jsonl'\n",
    "\n",
    "\"\"\"\n",
    "LANG_NAME = 'spanish'\n",
    "LANG_CODE = 'es-ES'\n",
    "REGION_CODE = 'es'\n",
    "SPACY_DICT = 'es_core_news_sm'\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "LANG_NAME = 'japanese'\n",
    "LANG_CODE = 'ja-JP'\n",
    "REGION_CODE = 'ja'\n",
    "SPACY_DICT = 'ja_core_news_sm'\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "LANG_NAME = 'russian'\n",
    "LANG_CODE = 'ru-RU'\n",
    "REGION_CODE = 'ru'\n",
    "SPACY_DICT = 'ru_core_news_sm'\n",
    "\"\"\"\n",
    "\n",
    "LANG_NAME = 'vietnamese'\n",
    "LANG_CODE = 'vi-VN'\n",
    "REGION_CODE = 'vi'\n",
    "SPACY_DICT = ''\n",
    "from spacy.lang.vi import Vietnamese\n",
    "\n",
    "\n",
    "OUTPUT_PATH = '../artifacts/synthetic_wikigoogle_top_n/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INPUT_FILE, 'r', encoding='utf-8') as fp:\n",
    "    mkqa_dataset = list(fp)\n",
    "\n",
    "mkqa_dataset = [json.loads(jline) for jline in mkqa_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if LANG_NAME == 'vietnamese':\n",
    "    from spacy.lang.vi import STOP_WORDS as STOP_WORDS_VI\n",
    "    STOPWORDS = set([x for x in STOP_WORDS_VI if x])\n",
    "elif LANG_NAME == 'japanese':\n",
    "    from spacy.lang.ja import STOP_WORDS as STOP_WORDS_JA\n",
    "    STOPWORDS = set([x for x in STOP_WORDS_JA if x])\n",
    "elif LANG_NAME in nltk.corpus.stopwords.fileids():\n",
    "    STOPWORDS = set(nltk.corpus.stopwords.words(LANG_NAME))\n",
    "else:\n",
    "    STOPWORDS = set()\n",
    "\n",
    "len(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_num(text):\n",
    "    try:\n",
    "        return int(text)\n",
    "    except:\n",
    "        return float(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Search functions\n",
    "\n",
    "Useful resources:\n",
    "- API usage: https://developers.google.com/custom-search/v1/reference/rest/v1/cse/list\n",
    "- Free API Key: https://developers.google.com/custom-search/v1/introduction\n",
    "- Setup Search Engine and get ID: https://cse.google.com/\n",
    "\n",
    "Non-free API Key can be obtained from the Google's console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'XXXX'\n",
    "SEARCH_ENGINE_ID = 'XXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query, top_results=5, lang_code=LANG_CODE, region_code=REGION_CODE,\n",
    "                  recall=False, site_restrict=True):\n",
    "    query = re.sub(r'[\\u0060\\u00B4\\u2018\\u2019]', '\\'', query)\n",
    "    query = re.sub(r'[\\u201C\\u201D]', '\"', query)\n",
    "    query = re.sub(r'\"', '', query)\n",
    "    \n",
    "    quota_user = '%s%d' % (region_code, np.random.randint(1, 10000000))\n",
    "    params = {\n",
    "        'quotaUser': quota_user,\n",
    "        'key': API_KEY,\n",
    "        'cx': SEARCH_ENGINE_ID,\n",
    "        'q': query,\n",
    "        'hl': lang_code,\n",
    "        'gl': region_code,\n",
    "    }\n",
    "    if site_restrict:\n",
    "        url = 'https://www.googleapis.com/customsearch/v1/siterestrict'\n",
    "    else:\n",
    "        url = 'https://www.googleapis.com/customsearch/v1'\n",
    "    \n",
    "    r = requests.get(url=url, params=params)\n",
    "    if r.status_code == 429:\n",
    "        print(quota_user, r.text)\n",
    "        raise Exception('GCloud limit reached!')\n",
    "    elif r.status_code != 200:\n",
    "        #print('')\n",
    "        #print('GSearch - HTTP Status: %d - Query: %s' % (r.status_code, query))\n",
    "        print(r.text)\n",
    "        raise Exception('GSearch - HTTP Status: %d - Query: %s' % (r.status_code, query))\n",
    "        return []\n",
    "\n",
    "    raw_data = r.json()\n",
    "    \n",
    "    try:\n",
    "        if 'items' not in raw_data:\n",
    "            if recall:\n",
    "                # If already this method has been re-called\n",
    "                return []\n",
    "            elif 'spelling' in raw_data and 'correctedQuery' in raw_data['spelling']:\n",
    "                return google_search(query=raw_data['spelling']['correctedQuery'],\n",
    "                                     top_results=top_results,\n",
    "                                     lang_code=lang_code,\n",
    "                                     region_code=region_code,\n",
    "                                     recall=True)\n",
    "            else:\n",
    "                print('GSearch - No items - Query: %s' % (query))\n",
    "                return []\n",
    "                #raise Exception('No items')\n",
    "        else:\n",
    "            parsed_data = []\n",
    "            for item in raw_data['items']:\n",
    "                if 'title' not in item or 'link' not in item:\n",
    "                    # Bad links\n",
    "                    continue\n",
    "                elif re.search(r'\\.pdf', item['link']):\n",
    "                    # Skip pdfs\n",
    "                    continue\n",
    "                parsed_data.append({\n",
    "                    'title': item['title'],\n",
    "                    'url': item['link'],\n",
    "                })\n",
    "            return parsed_data[:top_results]\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print('Query: %s' % query)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"That '70s Show - Wikipedia, la enciclopedia libre\",\n",
       "  'url': 'https://es.wikipedia.org/wiki/That_%2770s_Show'},\n",
       " {'title': 'Brooke Shields - Wikipedia, la enciclopedia libre',\n",
       "  'url': 'https://es.wikipedia.org/wiki/Brooke_Shields'},\n",
       " {'title': \"That '70s Show - Viquipèdia, l'enciclopèdia lliure\",\n",
       "  'url': 'https://ca.wikipedia.org/wiki/That_%2770s_Show'},\n",
       " {'title': 'Jenna Fischer - Wikipedia, la enciclopedia libre',\n",
       "  'url': 'https://es.wikipedia.org/wiki/Jenna_Fischer'},\n",
       " {'title': 'Bobcat Goldthwait - Wikipedia, la enciclopedia libre',\n",
       "  'url': 'https://es.wikipedia.org/wiki/Bobcat_Goldthwait'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'quién interpreta a pam en aquellos maravillosos 70'\n",
    "google_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'フェルナンド・アロンソ - Wikipedia',\n",
       "  'url': 'https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A7%E3%83%AB%E3%83%8A%E3%83%B3%E3%83%89%E3%83%BB%E3%82%A2%E3%83%AD%E3%83%B3%E3%82%BD'},\n",
       " {'title': 'F1歴代記録 - Wikipedia',\n",
       "  'url': 'https://ja.wikipedia.org/wiki/F1%E6%AD%B4%E4%BB%A3%E8%A8%98%E9%8C%B2'},\n",
       " {'title': 'F1ドライバーズチャンピオンの一覧 - Wikipedia',\n",
       "  'url': 'https://ja.wikipedia.org/wiki/F1%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC%E3%82%BA%E3%83%81%E3%83%A3%E3%83%B3%E3%83%94%E3%82%AA%E3%83%B3%E3%81%AE%E4%B8%80%E8%A6%A7'},\n",
       " {'title': '2006年のF1世界選手権 - Wikipedia',\n",
       "  'url': 'https://ja.wikipedia.org/wiki/2006%E5%B9%B4%E3%81%AEF1%E4%B8%96%E7%95%8C%E9%81%B8%E6%89%8B%E6%A8%A9'},\n",
       " {'title': 'ミハエル・シューマッハ - Wikipedia',\n",
       "  'url': 'https://ja.wikipedia.org/wiki/%E3%83%9F%E3%83%8F%E3%82%A8%E3%83%AB%E3%83%BB%E3%82%B7%E3%83%A5%E3%83%BC%E3%83%9E%E3%83%83%E3%83%8F'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'フェルナンドアロンソは誰ですか？'\n",
    "google_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_article(url):\n",
    "    # Get wiki region and page ID\n",
    "    matches = re.search(r'https?://(?:www)?(.+)\\.wikipedia\\.org/(?:wiki|.+-.+)/([^&]+)', url)\n",
    "    if not matches:\n",
    "        print('Unexpected Wiki URL format: %s' % url)\n",
    "        raise Exception('Unexpected Wiki URL format: %s' % url)\n",
    "        #return None\n",
    "        \n",
    "    wiki_region = matches[1]\n",
    "    page_id = matches[2]\n",
    "    \n",
    "    api_url = 'https://%s.wikipedia.org/w/api.php' % wiki_region + \\\n",
    "        '?action=parse' + \\\n",
    "        '&page=%s' % page_id + \\\n",
    "        '&prop=text' + \\\n",
    "        '&format=json'\n",
    "        #'&section=1' + \\\n",
    "    \n",
    "    r = requests.get(api_url)\n",
    "    if r.status_code != 200:\n",
    "        print('')\n",
    "        print('Unexpected HTTP Status: %d - %s' % (r.status_code, url))\n",
    "        raise Exception('Unexpected HTTP Status: %d' % r.status_code)\n",
    "        #return None\n",
    "    \n",
    "    json_data = r.json()\n",
    "    if 'parse' not in json_data:\n",
    "        # Not found\n",
    "        return ''\n",
    "    article = json_data['parse']['text']['*']\n",
    "    \n",
    "    parsed_wikicode = mwparserfromhell.parse(article)\n",
    "    article = parsed_wikicode.strip_code()\n",
    "    \n",
    "    # Clean wiki rubbish\n",
    "    article = re.sub(r'\\[[^\\]]+\\]+', ' ', article)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paragraphs(text, min_length=50, max_length=1300, group_max_length=1000):\n",
    "    paragraphs = re.split(r'\\n\\n*', text)\n",
    "    paragraphs = [x.strip() for x in paragraphs]\n",
    "    paragraphs = [re.sub(r'[\\u200b\\xa0 ]+', ' ', x) for x in paragraphs]\n",
    "    paragraphs = [x for x in paragraphs if len(x) > 5]\n",
    "    \n",
    "    # Split big paragraphs\n",
    "    measured_paragraphs = []\n",
    "    for p in paragraphs:\n",
    "        if len(p) > max_length:\n",
    "            # Big paragraph must be split\n",
    "            p_sentences = nltk.tokenize.sent_tokenize(p)\n",
    "            grouped_sentences = ''\n",
    "            k = 0\n",
    "            while k < len(p_sentences):\n",
    "                sentence = p_sentences[k]\n",
    "                if len(grouped_sentences) > group_max_length:\n",
    "                    measured_paragraphs.append(grouped_sentences)\n",
    "                    grouped_sentences = ''\n",
    "                else:\n",
    "                    grouped_sentences = ('%s %s' % (grouped_sentences, sentence)).strip()\n",
    "                    k += 1\n",
    "        elif len(p) >= min_length:\n",
    "            # The paragraph is not too small\n",
    "            measured_paragraphs.append(p)\n",
    "\n",
    "    return measured_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Para otros usos de este término, véase Pearl Jam (desambiguación).', 'Pearl JamPearl Jam en Oakland, 2013.Datos generalesOrigen Seattle, Washington, Estados UnidosEstadoActivoInformación artísticaGénero(s)Rock alternativo', 'Hard rockPeríodo de actividad1990-presenteDiscográfica(s)J RecordsEpic RecordsUniversal Music GroupMonkeywrench RecordsWebSitio webSitio OficialMiembrosEddie VedderMike McCreadyStone GossardJeff AmentMatt CameronKenneth GasparExmiembrosDave KrusenMatt ChamberlainDave AbbruzzeseJack Irons', 'Pearl Jam es un grupo de grunge formado en Seattle, Estados Unidos, en el año 1990, con integrantes de las bandas Mother Love Bone y Temple of the Dog. Con la edición de su álbum debut Ten en 1991, Pearl Jam irrumpiría con fuerza en el ámbito musical alternativo. Junto a Nirvana, Alice in Chains, Stone Temple Pilots y Soundgarden están considerados como una de las bandas más grandes e influyentes de toda la escena del movimiento Grunge. Sus miembros fundadores y que aun siguen en el grupo son Eddie Vedder (voz), Mike McCready (guitarra principal), Stone Gossard (guitarra rítmica) y Jeff Ament (bajo).Pese a ser reconocidos como uno de los grupos más importantes e influyentes del grunge, Pearl Jam siempre destacó por un rock con toques más melódicos e influencias de grupos de rock de los años 1960 y 70 como The Who, Led Zeppelin o The Doors. Sus miembros siempre se han caracterizado por su rechazo a determinadas prácticas comunes en la industria musical, como por ejemplo la realización de vídeos promocionales; también es conocido su boicot a la empresa Ticketmaster.', 'La revista Rolling Stone los describió en 2006 como un grupo que \"se pasó la mayor parte de la década pasada destruyendo su propia fama\". Pearl Jam es considerado uno de los grupos más importantes de la década de 1990. Hasta la fecha, el grupo ha vendido 30 millones de álbumes en los Estados Unidos, así como una cantidad aproximada de 70 millones de discos en todo el mundo. Pearl Jam ha sobrevivido y superado en ventas a muchos de sus contemporáneos de la escena del rock alternativo de los noventa, y está considerada una de las bandas más influyentes de la década. El crítico de música Stephen Thomas Erlewine, de la revista musical Allmusic, califica a Pearl Jam como \"la banda de rock norteamericana más popular de los 90\". Los álbumes Vitalogy y Ten han sido incluidos por la revista Rolling Stone en su lista de los 500 mejores discos de la historia. La banda ha sido incluida en el Rock and Roll Hall of Fame y su cantante Eddie Vedder figura en la séptima posición de la lista de los 100 mejores cantantes de todos los tiempos elaborada por Rolling Stone.El grupo estaba originalmente compuesto por Stone Gossard (guitarra rítmica), Jeff Ament (bajo), Mike McCready (guitarra principal), Eddie Vedder (voz) y Dave Krusen (batería).', '1.6 El cambio a J Records y el álbum homónimo (2006–2008)', 'La historia de Pearl Jam se remonta a la década de 1980. Los orígenes de la banda se encuentran en Green River, grupo de grunge formado en 1983 con los restos de otras bandas de la escena de Seattle. Green River estaba integrado originalmente por Stone Gossard (del grupo March of Crimes y The Ducky Boys) a la guitarra, Jeff Ament (de Deranged Diction) al bajo, el cantante Mark Arm (exmiembro de los grupos Mr. Epp, Spluii Numa y Limp Richerds, y después miembro de Mudhoney), el guitarrista Steve Turner (exmiembro de Mr. Epp, The Limp Richerds y The Ducky Boys, y después miembro de Mudhoney) y el batería Alex Vincent. Green River llegó a grabar algunos EP y a aparecer en varias recopilaciones de artistas de su discográfica Sub Pop, pero finalmente se desintegró en 1987. Son recordados como uno de los primeros grupos importantes del naciente género grunge de Seattle. Después de la ruptura, Arm y Turner crean Mudhoney, mientras que Gossard y Ament comienzan a organizar su nuevo proyecto. Hacia 1988 se unen al cantante Andrew Wood (exmiembro de Malfunkshun) y empiezan a darle forma al grupo que se convertiría en Mother Love Bone.', 'Junto con el guitarrista Bruce Fairweather y el baterista Greg Gilmore, se introducen cada vez más en la escena de Seattle y comienzan a llamar la atención por su estilo, en el que se fusionaba el glam rock con el punk. En 1989 logran que la compañía discográfica PolyGram los contrate, e inician las grabaciones de lo que sería su primer álbum, de nombre Apple, proyectado para lanzarse en 1990. Semanas antes del lanzamiento del álbum, Andrew Wood muere por una sobredosis de heroína, el 19 de marzo de ese año. Mother Love Bone se desintegra tras la muerte de Wood, por lo que Ament y Gossard comienzan una vez más la búsqueda de personal para formar un nuevo grupo; en 1990 reclutan al guitarrista Mike McCready (exmiembro de Shadow) y con él comienzan a tocar como trío de manera informal. Durante este periodo Chris Cornell, cantante de Soundgarden y amigo personal de Wood, escribe un par de canciones en su homenaje y le pide a Ament, Gossard y McCready que le ayuden a grabarlas. El proyecto con el tiempo crece hasta convertirse en un álbum completo de homenaje, que toma el nombre de Temple of the Dog en referencia a la letra de la canción \"Man of Golden Words\" de Mother Love Bone.', \"Sin contar aún con batería ni cantante, el trío Ament/Gossard/McCready comienza la búsqueda de los nuevos miembros del grupo. Para acelerar la búsqueda, graban una maqueta de sus composiciones más recientes ayudados por Matt Cameron en la batería y que titularon The Gossman Project. La búsqueda la hacen no solo en la escena de Seattle. Una de las personas con las que aún no había tenido contacto es Jack Irons, exbatería de Red Hot Chilli Peppers. Irons les pide una demo para poder repartirla entre sus conocidos; le entregan un extracto de cinco canciones del Gossman Project (Conocido actualmente entre los seguidores del grupo como The Stone Gossard Demo '91). Dicha grabación contiene las canciones conocidas actualmente como Once, Footsteps, Alive, Black y Alone, todas ellas en versión instrumental. Lo que sucede a continuación determinará el futuro del grupo: Irons, en lugar de conseguirles un batería, le da la grabación a su compañero de baloncesto y surfista de San Diego el cantante Eddie Vedder, quien en ese momento trabajaba como empleado en una gasolinera y había sido cantante del grupo Bad Radio.\", 'La historia que se relata es que Vedder, una vez recibida la demo, la escucha durante toda la noche y que a la mañana siguiente mientras surfea como era su costumbre, con música dando vueltas aún por su cabeza le van viniendo las letras a la mente. Ya en casa, aprovechando ese momento de inspiración, graba las voces de tres de las canciones, renombrándolas como \"Alive\", \"Once\" y \"Footsteps\". Vedder concibe estas canciones, como afirmará después, en forma de mini-ópera, conocida desde entonces como la \"Trilogía Momma-son\". Vedder envía de vuelta a Seattle su demo, que impresiona fuertemente a Mike, Stone, Jeff y a su nuevo miembro, el baterista Dave Krusen. En menos de una semana Vedder está en Seattle e inmediatamente dan comienzo las sesiones de lo que será el disco de la nueva banda, aún sin nombre. Al mismo tiempo, estando casi listo el proyecto de Temple of the Dog, Chris Cornell invita a Vedder a que canten juntos el tema que será el sencillo de ese disco, \"Hunger Strike\". De esa manera, la alineación definitiva de dicho proyecto queda con Cornell y Vedder en las voces, Jeff Ament al bajo, Stone Gossard y Mike McCready a la guitarra y Matt Cameron a la batería.', 'Los meses siguientes avanzan rápido para la naciente banda: en noviembre inician la grabación de su primera demo profesional. Durante febrero de 1991 salen de gira por toda la costa oeste de los Estados Unidos como teloneros de Alice in Chains, y para marzo entran de nuevo al estudio para comenzar la grabación de su primer disco.Debido al creciente interés que despierta la escena grunge de Seattle, Cameron Crowe, en ese entonces productor de la cadena estadounidense MTV, comienza a filmar una película cuyo escenario principal es el ambiente musical de la ciudad. Singles representó una excelente forma de dar a conocer al mundo lo que en ese entonces pasaba en Seattle. Eddie Vedder, Stone Gossard y Jeff Ament actúan en la película como miembros de la banda ficticia Citizen Dick, liderada por el protagonista Matt Dillon. Después de firmar con Epic Records, el grupo se ve obligado a cambiar su nombre por problemas comerciales. Aquí comienzan una serie de teorías acerca del origen del actual nombre de la banda, que ahora ya es un símbolo en la historia musical moderna: Pearl Jam.', 'Estando en puertas su debut discográfico Dave Krusen, aduciendo problemas personales debidos a su adicción al alcohol, abandona el grupo tras la fiesta de presentación de la película Singles. La salida de Krusen da inicio al constante problema de la banda con los bateristas, ya que por diversas razones ha contado con cinco miembros diferentes hasta ahora. Krusen es sustituido por Matt Chamberlain, que había tocado anteriormente con Edie Brickell and New Bohemians. Después de algunos conciertos (incluido el concierto en el que se filmó el vídeo de la canción \"Alive\" ), Chamberlain deja Pearl Jam para unirse al grupo de apoyo del programa Saturday Night Live. Antes de su salida, Chamberlain les recomienda a Dave Abbruzzese como su reemplazo; Abbruzzese se une al grupo durante la gira de apoyo del nuevo disco y formará parte de Pearl Jam durante dos álbumes más.El primer disco del grupo ve la luz por fin el 27 de agosto de 1991 con el título de Ten, en homenaje a Mookie Blaylock (dicho jugador utilizaba el número diez en su camiseta) y la canción \"Alive\" se lanza como su primer sencillo.', 'El disco, junto al Nevermind de Nirvana, es considerado uno de los motores que dieron al movimiento musical de Seattle su auge mundial.Durante finales de 1991 Pearl Jam se dedica a telonear a varias bandas importantes como Smashing Pumpkins o Red Hot Chilli Peppers, pero es con el lanzamiento de Ten con el que el grupo comienza a realizar giras, principalmente durante 1992. Para febrero de ese año el grupo da inicio a su primera gira europea; al regresar a Seattle, deben suspender un concierto ya que la asistencia al mismo (25.000 personas) rebasa ampliamente las expectativas que se tenían.El lunes 16 de marzo de 1992 graban para la cadena MTV un concierto de su serie Unplugged, que se transmite el 13 de mayo, y que no es lanzado comercialmente hasta marzo de 2009. En junio regresan a Europa, esta vez tocando ante grandes cantidades de público, siendo las actuaciones más importantes su concierto en el PinkPop festival en los Países Bajos y el festival Rock am Ring en el circuito de Nürburgring, Alemania, donde tocan ante cincuenta mil personas.', '\"Jeremy\" se convirtió en unos de los sencillos más vendidos de la década de los 90.', 'En agosto de 1992 es lanzado el vídeo musical del tema \"Jeremy\", tercer sencillo del álbum Ten y uno de sus vídeos musicales más famosos. A la larga, este provocaría el segundo conflicto de la banda, esta vez contra las cadenas de televisión musicales (principalmente MTV), ya que el vídeo fue censurado y en ocasiones prohibido porque, en opinión del grupo, se daba mucha más importancia al impacto visual del vídeo y los conflictos que este pudiera ocasionar que a la propuesta artística. Pearl Jam aún graba un vídeo más para la canción \"Oceans\" (que solo es lanzado en Europa), pero a partir de entonces se niegan a grabar nuevos vídeos promocionales para sus canciones. Jeff Ament resume la actitud del grupo al comentar en una entrevista: \"No queremos que la gente recuerde nuestras canciones como vídeos\". Mantendrán esta postura durante seis años.A inicios de 1993 la fama del grupo era inmensa, y ello hace que comiencen sentirse incómodos, sobre todo Eddie Vedder, que lleva la mayor parte de la carga de la popularidad del grupo.', 'Ese año Vedder es invitado por los miembros sobrevivientes de The Doors para cantar algunas canciones del grupo durante la ceremonia de su ingreso al Salón de la Fama del Rock. En junio el grupo sale de nuevo de gira por Europa como teloneros de Neil Young y U2.El 19 de octubre sale a la venta Vs., segundo álbum de la banda, vendiendo en su primera semana 950.378 copias. En el disco se deja ver algo de la ira y rabia que sienten contra los medios y todo el entorno de la fama en el que se sienten encerrados. El acoso por parte de las revistas especializadas crece; Rolling Stone y Spin Magazine sacan entrevistas y reportajes sobre la banda, e incluso la revista Time pone a Vedder en su portada el 25 de octubre de ese año. En ese número de la revista se incluye un artículo sobre la creciente popularidad del grunge. Vedder se muestra enojado por la utilización de la fotografía de la portada y por la forma en que el grupo es presentado en el artículo. Se convertirá en el tercer conflicto del grupo: a partir de ese momento su relación con la prensa es más y más tensa, hasta el grado de negar entrevistas a cualquier medio, terminar con las ruedas de prensa y dejar de aparecer en programas de televisión de forma regular.', 'Este periodo comienza en 1994 y da inicio a una de las etapas más complejas del grupo. Tras el éxito de Pearl Jam en sus dos últimos álbumes de estudio, la banda se satura e inicia una campaña para \"destruir\" su fama. Esto se complementa con la muerte de Kurt Cobain en abril de 1994. La muerte del vocalista de Nirvana conllevó al fin del grunge en la escena mainstream, y también se originaron conflictos internos en el grupo por la predominancia de Eddie Vedder en la composición de canciones.A inicios del año el grupo sigue en gira, continuando con la segunda parte de la gira promocional del álbum Vs. El 1 de marzo de 1994, Pearl Jam anuncia su intención de mantener los precios de los conciertos de esa gira por debajo de los 20 dólares, ya que consideraba que la empresa Ticketmaster aprovechaba su posición de agencia de ventas dominante en Estados Unidos para perjudicar tanto a los grupos como a los fanes que iban a verlos. El siguiente paso fue el anuncio posterior de que Pearl Jam continúa con la gira sin contar con los servicios de Ticketmaster.', 'Con esto inicia uno de los conflictos legales más importantes de la década y que marcará el futuro del grupo. Las consecuencias de la demanda contra Ticketmaster se dejaron sentir, en mayo de 1994 el grupo se ve obligado a cancelar sus giras, en junio, Jeff Ament y Stone Gossard (los principales promotores de esta demanda) comparecen ante un subcomité de la cámara de representantes de los Estados Unidos, testificando en el litigio de monopolio levantado contra la empresa; terminadas las sesiones de grabación del tercer disco de la banda, Dave Abbruzzese deja el grupo el 1 de agosto, aduciendo problemas personales, pero todo indica que fue por diferencias con el resto del grupo por el asunto Ticketmaster (principalmente con Stone Gossard). Para cubrir con sus compromisos pendientes, Vedder le pide a su amigo Jack Irons que reemplace a Abbruzzese en la batería, debutando el 1 de octubre en el concierto Bridge School Benefit. Sin embargo, la secuela más dolorosa que deja el conflicto legal, tanto para la banda como para sus seguidores, es la dramática reducción de sus conciertos en vivo en 1994 y 1995 (de 150 en el periodo 92-93 a un poco más de 80 en el periodo 94-95), provocando que durante todo 1994 no realicen giras fuera de los Estados Unidos y prácticamente no ofrecer conciertos por casi tres años en dicho país.', 'A pesar de este clima de incertidumbre, la expectación por la tercera entrega del grupo es grande. El 22 de noviembre se lanza a la venta Vitalogy en edición especial en vinilo, logrando una cantidad de ventas muy importante a pesar de que el formato en vinilo ya comenzaba a quedar descontinuado por las compañías discográficas. Unos días después es lanzada la versión en disco compacto, alcanzado ventas de 877.000 copias en su semana de debut (el segundo lugar con más ventas en la historia en su primera semana). A pesar de ser un disco difícil y duro, expresa muy bien el momento generacional que se estaba viviendo. 1995 es un año de conflictos internos. Se dice que comienzan tensiones entre Vedder y el resto de la banda, hasta el grado que Jeff Ament abandona al grupo durante un tiempo, con lo que se difunden los primeros rumores de una posible desintegración. Sin embargo también es un año de cambio y regeneración al interior del grupo. Durante este año los conciertos vuelven a darse poco a poco, gracias a una pequeña compañía de venta de boletos que, ignorando las presiones de Ticketmaster, accede a manejar sus conciertos (a pesar de que varios tienen que ser suspendidos).', 'Para evitar la ruptura, los miembros del grupo se dedican a buscar proyectos alternos que ayuden a aliviar la tensión que empieza a surgir entre ellos. Es durante esta época en la que cada uno de los miembros del grupo comienza a expandirse y a crear grupos alternos a Pearl Jam o a involucrarse en nuevos ámbitos, relacionados o no con lo musical. También como grupo comienzan a realizar otro tipo de proyectos. Uno de los más significativos es un proyecto radiofónico, donde Pearl Jam se dedica a transmitir en vivo a grupos de la escena grunge como Soundgarden, Mudhoney o Mad Season y al mismo tiempo canciones de la misma banda. Este proyecto fue transmitido el 8 de enero de 1995 y es llamado Self-Pollution Radio. Durante estas retransmisiones, Eddie Vedder anuncia que Jack Irons oficialmente se convierte en su nuevo baterista. El otro gran proyecto de este año para el grupo, y que a futuro los ayuda a cambiar su rumbo artístico, es participar como banda de apoyo para las grabaciones del nuevo disco de Neil Young, llamado Mirror Ball.', 'Sin las presiones de ser ellos los estelares, el grupo logra una cohesión enorme durante las sesiones, consiguiendo un gran trabajo. En 1996, con un Pearl Jam renovado y relajado, se dan inicio a las sesiones para su cuarto disco, las que dan como resultado el álbum más discutido del grupo hasta ahora, el polémico No Code. Desde el lanzamiento del primer sencillo \"Who You Are\" se pronosticaba un cambio drástico en el sonido del grupo. Experimentación es la palabra que define al nuevo disco, algo que muchos fanes del grunge y varios críticos no aceptaron en el grupo. No Code es lanzado exactamente cinco años después que Ten y debuta en el número 35 del Billboard Hot 100, el más bajo hasta entonces.Sin embargo, el logro más grande de No Code es que le da un nuevo impulso al grupo, reencontrando la forma de convivir con la fama sin tener que sacrificar la propuesta artística. Las canciones contenidas en el disco significan un avance en cuanto a lo que venían realizando en sus discos anteriores, con un contenido mucho más espiritual en las letras y un ritmo más relajado a diferencia de la rabia de Vs. o Vitalogy.', 'El periodo que comprende estos años puede ser considerado como contradictorio. Mientras que por un lado el grupo sufre varios golpes que los ponen de nueva cuenta al borde de la separación, por otro van adquiriendo poco a poco una gran madurez tanto artística como personal y de grupo. 1998 es el año que ve surgir uno de los discos más aclamados de la banda, Yield. En este álbum se recogen todas las enseñanzas logradas en su predecesor No Code, combinándolas con el rock duro y directo que siempre los caracterizó. De igual forma el grupo poco a poco comienza a reabrirse a la prensa y la televisión, ya que para promover su nuevo disco aparecen en programas de televisión como el \"Late Show with David Letterman, además de lanzar su segundo proyecto radiofónico, esta vez titulado Monkey Wrench Radio. Además, para apoyar el lanzamiento del álbum, Pearl Jam anuncia una nueva gira a través de todos los Estados Unidos y parte de Oceanía y Hawái, misma que está planeada para durar todo el año completo.', 'Parecía que el grupo regresaba a la normalidad, pero estando ya en plena gira, Jack Irons debe dejar el grupo por problemas de salud. Este fue un golpe importante para el grupo, ya que Irons tenía lazos de amistad muy fuertes principalmente con Eddie Vedder. Providencialmente no tienen dificultad en encontrar un reemplazo, ya que casi de inmediato le solicitaron a un viejo conocido, Matt Cameron, integrarse a la banda para cubrir el hueco dejado por Irons. Cameron en ese momento se encontraba desempleado ya que un año atrás Soundgarden se había desintegrado.Nuevos proyectos ayudan también a reafirmar la presencia del grupo. Lanzan a la venta su primera realización en vídeo (el documental Single Video Theory) y su primer álbum en vivo oficial (el Live On Two Legs), además de lanzar su primer video promocional en seis años para la canción \"Do the Evolution\", el cual es grabado completamente en animación dirigido por Todd McFarlane, creador del cómic Spawn.Como lo habían hecho desde que comenzaron como grupo, Pearl Jam distribuye a su club de fanes oficial un disco de colección, el famoso X-Mas Single (sencillo de Navidad).', 'Fotografía de la Nebulosa MyCn 18 o Reloj de arena tomada desde el Telescopio espacial Hubble. Esta imagen fue usada por el grupo para ilustrar la portada del álbum Binaural.', 'La demanda que tienen las canciones del X-Mas Single se vuelve tan grande, que el grupo decide, el 8 de junio de 1999, lanzar de manera comercial el sencillo \"Last Kiss\"/ \"Soldier of Love\". Una semana después, ambas canciones son incluidas en el disco a beneficio de los refugiados de Kosovo No Boundaries, lo cual impulsa las ventas del sencillo aún más. Antes de que terminara el mes, el sencillo alcanza el número 2 en la lista Billboard Hot 100 (su sencillo que mejor puesto ha ocupado hasta 2007). Ya para abril de 2000, el álbum recauda más de 6,7 millones de dólares estadounidenses, y el sencillo \"Last Kiss\" se convierte en el éxito comercial más grande que Pearl Jam ha tenido hasta la fecha.El año 1999 termina ya sin grandes sobresaltos, comenzando las sesiones de su nuevo álbum el 1 de septiembre, ya con Matt Cameron como baterista de planta. A finales de año lanzan la página web oficial del club de fanes del grupo, llamada en ese entonces como Tenclub.net.El sexto disco de la banda, Binaural ve la luz con los primeros meses de 2000, el 16 de mayo, y casi simultáneamente anuncian su primera gira europea en 5 años.', 'Para el 23 de mayo se embarcan en una de las giras que les lleva a recorrer casi toda Europa y que marcará en muchas formas el destino del grupo.Desde los inicios del grupo, Pearl Jam ha sido, junto con Nirvana y U2, una de las bandas que más ha sido pirateada. Es posible encontrar un catálogo enorme de ediciones alternativas y actuaciones en vivo del grupo grabados de forma ilegal (o bootlegs, como se les conoce en el ámbito musical). Pearl Jam era consciente de esta actividad, hasta el punto que no solo la había permitido, sino que para la gira europea del 2000 anunció que lanzarían a la venta la totalidad de los conciertos en discos dobles. La idea original era ofrecer estos bootlegs oficiales solo al club de fanes, pero por cuestiones contractuales se vieron obligados a lanzar la totalidad de bootlegs, que al final de la gira de 2000 serían 72, en tiendas. De este modo nacen las famosas Bootleg Series de Pearl Jam. Hasta la fecha en cada una de sus giras han seguido ofreciendo sus bootlegs en vivo.Todo parece indicar que la gira europea terminaría de forma normal, sin embargo la tragedia alcanzó al grupo en uno de sus conciertos.', 'El 30 de junio de 2000, mientras Pearl Jam actuaba en el Festival Roskilde en Dinamarca, la multitud comienza a avanzar hacia el escenario, aplastando contra las bardas de contención a la gente que se encuentra en la parte más cercana al escenario, todo esto ante los mismos ojos de la banda. Un Eddie Vedder atónito interrumpe el concierto y pide a través del micrófono que la gente dé un paso hacia atrás, pero todo resulta inútil, 9 personas mueren aplastadas debido al empuje de la gente de la parte frontal. Ante la tragedia el grupo se tambalea. Se cancelan los últimos dos conciertos de la gira europea y las ideas de separación comienzan a rondar al interior del grupo. El resultado de la investigación policial sobre la tragedia revela que fueron problemas técnicos los que provocaron el suceso, evitando con esto en cierta manera que el grupo se sienta responsable de las muertes y se separe por esta causa. El grupo decide continuar con sus planes, comenzando con la gira norteamericana, donde además se incluye el concierto donde celebran su décimo aniversario.', 'Este período está caracterizado por el fuerte activismo en los que los miembros del grupo (y en especial Eddie Vedder) se ven involucrados, influidos principalmente por las actitudes del gobierno estadounidense frente a los ataques del 11 de septiembre y por la actitud que tomó la banda posterior a la Tragedia de Roskilde.Durante gran parte del año el grupo se encierra para la grabación de su séptimo álbum de estudio, así que sus interpretaciones en vivo son muy pocas. Sobresale la participación de Eddie Vedder en la introducción al Salón de la Fama del Rock and Roll de The Ramones, el 18 de marzo de 2002.Mientras se encontraban grabando en el estudio, el 19 de abril de 2002, se anuncia la muerte de Layne Staley, cantante del grupo Alice in Chains, causada por una sobredosis de heroína. La noticia impacta fuertemente al grupo e inspira a Eddie Vedder a escribir una canción dedicada a Staley titulada \"4/20/02\". La canción no se lanza hasta 2004, como parte de la recopilación de lados-B y rarezas del grupo llamada Lost Dogs.El nuevo disco comienza a ver la luz con el lanzamiento de su primer sencillo, titulado \"I Am Mine\", lanzado el 8 de octubre de 2002 y con el lanzamiento mundial de Riot Act el 12 de noviembre.', 'A pesar de la expectativa generada, el álbum solo vende 166.000 copias en su semana de lanzamiento (mucho menos de lo logrado por todos sus lanzamientos anteriores). Riot Act se caracteriza por un sonido más basado en el folk y la música experimental, apoyados por un órgano B3, ejecutado por un miembro no oficial del grupo, Kenneth Boom Gaspar, y que le da al álbum un sello inusual en el grupo en canciones como \"Love Boat Captain\" por ejemplo. Además, se incluye una canción titulada \"Arc\", un experimento vocal realizado por Vedder a manera de tributo a las nueve personas que murieron en el Festival Roskilde en junio de 2000. \"Arc\" fue interpretada en vivo durante la gira de 2003 solamente en nueve ocasiones y fue eliminada de los bootlegs correspondientes como un acto de respeto. El 2003 inicia con la nueva gira mundial de la banda, la cual cubre originalmente Japón, Australia y los Estados Unidos. Esta gira pronto se vuelve controversial, ya que Vedder comienza a incluir un show anti-Bush cuando la banda interpreta la canción \"Bu$hleaguer\", el cual no siempre es bien recibido por los espectadores.', 'Mención aparte merece lo sucedido en el concierto inaugural de la gira norteamericana, realizado en la ciudad de Denver, el 1 de abril de 2003. En este concierto, el público queda atónito al ver como Eddie Vedder comienza a golpear una máscara del presidente George W. Bush. Mucha gente abuchea el acto y abandona el recinto ante la sorpresa de todo el grupo. Durante esta gira el grupo trata de hacer cosas nuevas en los conciertos. En algunas ocasiones dando recitales de más de 30 canciones, ofreciendo un espectáculo previo semi-acústico en Boston, o procurando repetir las menos canciones posibles entre cada concierto. Hacia mayo, el grupo anuncia una extensión de su gira norteamericana, en la cual se incluye por vez primera a México. La gira en México resulta diferente en varios aspectos, ya que previo a su primer concierto, el 17 de julio de 2003, el grupo ofrece su primera conferencia de prensa en casi 10 años. Además, el tercer concierto del grupo en la Ciudad de México es transmitido en vivo por radio y televisión a toda América Latina.Para esta gira Pearl Jam continua con su proyecto de ofrecer los bootlegs de sus conciertos del 2003, con la diferencia de que solo seis son lanzados a la venta al público, mientras que la totalidad de los conciertos solo son ofrecidos en su página web.2003 termina para ellos con nuevos lanzamientos.', 'Colaboran con el director Tim Burton con el tema \"Man of the Hour\" para su película Big Fish, editan su colección de dos discos de rarezas y lados B, Lost Dogs; y lanzan el Live at the Garden, DVD con el concierto realizado en el Madison Square Garden el 8 de julio de 2003. El año 2004 transcurre con muy poca actividad del grupo, ya que cada uno de los miembros se dedica a proyectos personales. De este año cabe destacar el fuerte activismo del grupo debido a que en los Estados Unidos se encuentra en año de elecciones presidenciales. Para reafirmar la postura anti-Bush que han asumido, Pearl Jam toca la canción \"Masters of War\", original de Bob Dylan en el programa Late Show with David Letterman del 30 de septiembre, como preámbulo a su participación en la gira Vote For Change (Voto por el cambio). Esta gira se realiza del 1 al 13 de octubre a lo largo de varias ciudades estadounidenses, acompañados de grupos como Dixie Chicks, Dave Matthews Band, R.E.M., Bruce Springsteen, todo esto como parte de la campaña de concienciación para evitar la reelección de George W. Bush como presidente.', 'Eddie Vedder, durante un concierto de Pearl Jam en 2009.', 'Para abril de 2005 anuncian la realización de una gira que abarca varias ciudades de Canadá. El 13 de julio realizan un concierto en la ciudad de Missoula, Montana, para apoyar la candidatura al Senado de los Estados Unidos de Jon Tester.El 1 de septiembre inicia su gira norteamericana con un concierto especial en el Anfiteatro Gorge, en las afueras de Seattle, interpretando un concierto acústico y eléctrico que dura poco más 3 horas (interpretan en total 36 canciones) y arrancan su gira canadiense al día siguiente en la ciudad de Vancouver, la cual los lleva a través de ciudades donde nunca antes habían tocado. Al mismo tiempo dan la noticia de que al concluir la gira canadiense realizarán su primera gira por toda Latinoamérica, comenzando el 22 de noviembre en Chile, luego en Argentina, más tarde en Brasil y finalizando en México. Para todos estos conciertos, el grupo anuncia que su nueva serie de Bootlegs serán solo lanzados en formato MP3 y distribuidos en su página web oficial. Este hecho marca un precedente ya que después del escándalo provocado por el programa Napster, las empresas discográficas y muchos grupos musicales se habían dedicado a satanizar el uso y venta de la música en formatos para ordenador.', 'El cambio a J Records y el álbum homónimo (2006–2008)', 'Los trabajos para el siguiente álbum del grupo comenzó después de la gira \"Vote for Change\" de 2004. En febrero de 2006, Clive Davis anuncia que Pearl Jam firmaba con su discográfica, J Records, la cual como Epic Records es parte de Sony Music Entertainment. El octavo álbum de estudio de la banda, Pearl Jam, fue lanzado el de 2 de mayo de 2006. Varios críticos consideraron que este álbum marcaba el retorno de la banda al estilo de sus primeros días, mientras que McCready, compara este material con lo hecho en Vs. Jeff Ament decía que \"El grupo tocó en un cuarto con todos juntos. Hay un tipo de inmediatez en la grabación, y eso es lo que estabamos buscando\". Chris Willman de Entertainment Weekly decía que \"En un mundo de niños haciendo el trabajo de hombres en el rock, Pearl Jam sale adelante con seriedad\". Los problemas socio-políticos de la época se reflejan en varias canciones del álbum, como en \"World Wide Suicide\", la cual es una crítica a la Guerra en Iraq y a la política exterior de los Estados Unidos.', 'Aún con esto, la canción llegó a lo más alto de las listas de Billboard Modern Rock, convirtiéndose en el primer número uno en dicha lista desde que \"Who you are\" lo consiguiera en 1996 y su primer número uno en cualquier lista desde que \"Given to fly\" lo consiguiera en 1998. De este álbum se extraerían también las canciones \"Life Wasted\" y \"Gone\" como sencillos.Para soportar su álbum homónimo, el grupo inició su gira mundial de 2006 la cual recorre Estados Unidos, Australia y, principalmente Europa, donde no habían tocado en 6 años. Dentro de la gira en Estados Unidos se incluyeron dos noches donde Pearl Jam sirvió de grupo abridor para Tom Petty and the Heartbreakers. También en esta gira se dio el regreso del grupo a los festivales de música, cuando fueron los grupos principales en Leeds y Reading, a pesar de que habían anunciado que no regresarían a dichos eventos desde la tragedia de Roskilde. Vedder comenzó ambos conciertos con una emotiva súplica al público para que se cuidaran unos a otros.', 'Además, durante el concierto en Leeds, Vedder comenta que la decisión de la banda para tocar en un festival por primera vez desde Roskilde no tuvo que ver nada con \"agallas\" sino con la confianza en el público.En 2007, Pearl Jam graba una versión para la canción de The Who \"Love, Reign o\\'er Me\" para la película \"Reign Over Me\", dirigida por Mike Binder. Esta canción se puso disponible por descarga en iTunes Music Store. En este año, Pearl Jam inicia una nueva gira de 13 fechas en Europa, además de encabezar nuevamente el festival Lollapalooza el 5 de agosto de 2007. En junio de 2007 lanzan el recopilatorio \"Live at the Gorge 05/06\", el cual documenta las presentaciones que realizan en el The Gorge Amphitheatre y, en septiembre de 2007 lanzan el DVD \"Immagine in Cornice\" que documenta los conciertos de la gira italiana de 2006.En 2008, Pearl Jam arranca una gira de 12 fechas en el este de Estados Unidos, incluyendo una presentación como grupo principal en el festival de Bonnaroo. En julio de 2008 se presentan en el tributo que la cadena VH1 le dedica a The Who junto con Foo Fighters, Incubus y The Flaming Lips.', 'El 7 de abril de 2017 la banda ingresa al Salón de la Fama del Rock and Roll, siendo los miembros incluidos Eddie Vedder, Stone Gossard, Jeff Ament, Mike McCready, Matt Cameron y Dave Krusen, baterista original de la banda que se reunió tras 25 años para interpretar Alive.', 'Comparados con otras bandas del movimiento grunge de inicios de los años 1990, el estilo de Pearl Jam es notablemente menos pesado y se remonta más hacia el rock clásico de los años 70. El grupo ha citado como influencias a varios grupos de punk y rock clásico, tales como The Who, Neil Young, Kiss y Ramones. El gran éxito del grupo ha sido atribuido en gran parte a su sonido, el cual fusiona \"los riffs del rock de estadio pesados de los 70 con el valor y la furia del post-punk de los 80, sin descuidar los ganchos ni los coros\". Pearl Jam ha ampliado su rango musical conforme avanzaban sus álbumes. Para Vitalogy de 1994, el grupo comienza a incorporar más influencias punk en su música. En No Code fue deliberado el rompimiento con el estilo musical de su álbum debut Ten. Aquí las canciones tienen elementos del garage rock, el worldbeat y la música experimental. Después del regreso al rock directo de sus primeras producciones que se da en Yield, el grupo se acerca a un rock más experimental con Binaural y al folk rock en Riot Act.', '↑ Hiatt, Brian (16 de junio de 2006). «The Second Coming of Pearl Jam». Rolling Stone. Archivado desde el original el 28 de mayo de 2007. Consultado el 22 de junio de 2007.', '↑ a b c Erlewine, Stephen Thomas. «Pearl Jam > Biography». Allmusic. Consultado el 22 de junio de 2007.', '↑ «Top Artists». RIAA. Archivado desde el original el 1 de julio de 2007. Consultado el 15 de julio de 2007.', '↑ Steuer, Eric (19 de mayo de 2006). «Pearl Jam Releases Its First Music Video In Eight Years Under a Creative Commons License». CreativeCommons.com. Archivado desde el original el 2 de julio de 2007. Consultado el 15 de julio de 2007.', '↑ Lampert, Eva (2 de marzo de 2006). «Self-Titled Pearl Jam Album Gets Release Date». ChartAttack.com. Consultado el 16 de agosto de 2007.', '↑ Erlewine, Stephen Thomas. «Pearl Jam Biography» (en inglés). All music. Consultado el 23 de noviembre de 2015.', '↑ «Green River Catalog». Sub Pop Records. Consultado el 10 de octubre de 2007.', '↑ Huey, Steve (13 de julio de 2005). «Green River Biography». All music. Consultado el 28 de febrero de 2007.', '↑ All Media Guide (2005). «Mother Love Bone Biography». VH1.com. Consultado el 28 de febrero de 2007.', '↑ Friend, Lonn M. (julio de 2002). «Heroes...and Heroin». RIP Magazine. Consultado el 27 de febrero de 2007.', '↑ Mother Love Bone. «Man Of Golden Words lyrics by MOTHER LOVE BONE». TS Rocks. Archivado desde el original el 8 de octubre de 2007. Consultado el 1 de marzo de 2007.', '↑ Footsteps tiene una historia curiosa, ya que, mientras que la letra en la versión de Temple of the Dog es original de Chris Cornell, la de la versión de Pearl Jam sería compuesta por Eddie Vedder, como parte de la Trilogía Mamasan. Para mayores datos consultar: Five Horizons (1999). «Footsteps». Five Horizon, Pearl Jam Fanzine. Consultado el 2 de abril de 2007.', '↑ a b c d e Crowe, Cameron (28 de noviembre de 1993). «Five Against the World». Rolling Stone. Consultado el 31 de octubre de 2007.', '↑ Conaty, Gavin. «Pearl Jam: Early Recordings History». Given to wail. Archivado desde el original el 20 de febrero de 2007. Consultado el 27 de febrero de 2007.', \"↑ Bruns, Jean; Rose Caryn. (1999). «The 'Momma-son' Trilogy Alive/Once/Footsteps». Five Horizons, Pearl Jam Fanzine. Consultado el 8 de marzo de 2007.\", '↑ Como dato curioso esta alineación, quitando solo a Chris Cornell, se convertiría en la alineación actual de Pearl Jam.', '↑ Bruns, Jean. (1999). «Pearl Jam 1990/1991 Concert Chronology». Five Horizons, Pearl Jam Fanzine. Consultado el 20 de marzo de 2007.', '↑ Gruhlke,. «Singles». Internet Movie Database. Consultado el 2 de abril de 2007.', '↑ Horowitz, Scott (4 de febrero de 2003 (última actualización)). «Extracto de una entrevista con Eddie Vedder donde narra los orígenes del nombre Pearl Jam». theskyiscrape.com. Archivado desde el original el 12 de febrero de 2007. Consultado el 27 de febrero de 2007.', '↑ Hiatt, Brian (29 de junio de 2006.). «The Second Coming of Pearl Jam.». Rolling Stone Magazine. Archivado desde el original el 4 de mayo de 2007. Consultado el 26 de abril de 2007.', '↑ Bernaola, Enrique (10 de marzo de 2011). «Dave Krusen: \"Siempre me arrepentí de dejar Pearl Jam\"». tiramillas.net. Consultado el 23 de noviembre de 2015.', '↑ a b Scanlon, Tom (24 de julio de 2003). «Drummer to the stars calls Seattle home» (en inglés). The Seattle Times. Consultado el 23 de noviembre de 2015.', '↑ Chamberlain, Matt. (2005). «Biography (En la página principal aparece la liga a esta sección)». mattchamberlain.com. Consultado el 20 de marzo de 2007.', '↑ Peiken, Matt (1993). «Dave Abbruzzese of Pearl Jam» (en inglés). Modern Drummer. Archivado desde el original el 29 de junio de 2012. Consultado el 23 de noviembre de 2015.', '↑ a b \"Pearl Jam: Timeline\" Archivado el 9 de enero de 2008 en la Wayback Machine.. pearljam.com.', \"↑ DeRogatis, Jim. Milk It!: Collected Musings on the Alternative Music Explosion of the 90's. Cambridge: Da Capo, 2003. ISBN 0-306-81271-1, pg. 58\", \"↑ Pearl Jam (30 de junio de 1994). «PJ's testimony before Congress regarding Ticketmaster». Five Horizons Pearl Jam Fanzine. Consultado el 7 de julio de 2008.\", \"↑ Pearl Jam (30 de junio de 1994). «PJ's testimony before Congress regarding Ticketmaster». Five Horizons Pearl Jam Fanzine. Consultado el 27 de febrero de 2007.\", '↑ a b Weisbard, Eric, et al. \"Ten Past Ten\". Spin Online. Agosto de 2001', '↑ Esta estadística fue sacada usando el Setlist Archive, contenido en la página The Sky is crape (En inglés)', '↑ Guitar World (marzo de 1998). «All For One: Pearl Jam Yield to the Notion That United They Stand and Divided They Fall». Five Horizons Pearl Jam Fanzine. Consultado el 29 de octubre de 2007.', '↑ Bilotti, Karen; Reynolds, John. (Transcriptores) (2002). «Self Pollution Radio complete transcription.». Monkey wrench radio. Consultado el 12 de abril de 2007.', '↑ Bishop, Jen; Eason, Sharon. (Transcriptores) (2002). «Monkey Wrench Radio complete transcription.». Monkey wrench radio. Consultado el 19 de abril de 2007.', '↑ «Taping/Camera Policy Guidelines». Sonymusic.com. 27 de mayo de 2006. Archivado desde el original el 11 de octubre de 2007. Consultado el 31 de octubre de 2007.', \"↑ Gundersen, Edna (31 de agosto de 2000). «Pearl Jam's Bootlegs Give Others the Boot». USA Today. Consultado el 31 de octubre de 2007.\", \"↑ Stout, Gene (1 de septiembre de 2000). «Pearl Jam's darkest hour». Seattle Pi. Archivado desde el original el 31 de diciembre de 2006. Consultado el 27 de febrero de 2007.\", '↑ BBC News Online (22 de octubre de 2000). «Safety plan for Roskilde festival». BBC Online. Consultado el 27 de febrero de 2007.', '↑ Hasta antes del incidente en Roskilde, \"Alive\" había sido interpretada en 19 de los 25 conciertos de la gira europea.', '↑ Five Horizons (4 de abril de 2003). «Pearl Jam: 2003 Concert Chronology Part 3». Fivehorizons.com. Consultado el 9 de noviembre de 2015.', '↑ BBC News Online (4 de abril de 2003). «Pearl Jam Bush stunt angers fanes». BBC Online. Consultado el 27 de febrero de 2007.', '↑ Zahlaway, Jon (4 de abril de 2003). «Pearl Jam responds to report on fan-walkout after anti-Bush display». Live Daily. Archivado desde el original el 23 de febrero de 2007. Consultado el 27 de febrero de 2007.', '↑ Los conciertos que son puestos a la venta son los de Perth, Australia; Tokio, Japón; y los de The State Collage, 2 conciertos de Nueva York y el realizado en Mansfield. De manera especial para México también fue puesto a la venta el primer concierto realizado en la Ciudad de México.', '↑ Jiménez, José Miguel (septiembre de 2004). «Vota por el cambio, Grupos contra Bush». Margen Cero. Consultado el 27 de febrero de 2007.', '↑ Crapshoot (o \"Crapshoot Rapture\" como se le conoce también) cambiaría su nombre a \"Comatose\" en la versión final del álbum Pearl Jam.', '↑ Bishop, Jen; Eason, Sharon. (Transcriptores) (9 de febrero de 2006). «Showbiz Tonight». CNN. Consultado el 3 de septiembre de 2007.', '↑ Adondeirhoy.com (16 de diciembre de 2011). «Concierto Pearl Jam en Costa Rica». Adondeirhoy.com. Consultado el 16 de diciembre de 2011.', '↑ Unterberger, Andrew (18 de noviembre de 2004). «Pearl Jam: Rearviewmirror». Stylus. Consultado el 31 de octubre de 2007.', '↑ Kerr, Dave. (mayo de 2006). «Explore and not Explode». The Skinny. Archivado desde el original el 11 de octubre de 2007. Consultado el 31 de octubre de 2007.', '↑ Easley, Jonathan (2 de mayo de 2006). «Pearl Jam». Prefix Magazine. Consultado el 31 de octubre de 2007.', '↑ Cross, Charles R. \"Better Man\". Guitar World Presents: Guitar Legends: Pearl Jam. Julio de 2006.', 'Clark, Martin. Pearl Jam & Eddie Vedder: None Too Fragile (2005). ISBN 0-85965-371-4', 'Jones, Allan. Pearl Jam - The Illustrated Story, A Melody Maker Book (1995). ISBN 0-7935-4035-6', 'Neely, Kim. Five Against One: The Pearl Jam Story (1998). ISBN 0-14-027642-4', 'Wikimedia Commons alberga una categoría multimedia sobre Pearl Jam.', 'Portada de la revista Rolling Stone del 28 de octubre de 1993', 'Portada de la revista TIME del 25 de octubre de 1995', 'Fotografía tomada durante el concierto del grupo en el fatídico Festival de Roskilde, 30 de junio de 2000, 15 minutos antes de que Pearl Jam detuviera el concierto', 'Declaración del grupo sobre la tragedia de Roskilde (en inglés)', 'Vote for Change — página oficial del movimiento (en inglés)', '.mw-parser-output .mw-authority-control{margin-top:1.5em}.mw-parser-output .mw-authority-control .navbox hr:last-child{display:none}.mw-parser-output .mw-authority-control .navbox+.mw-mf-linked-projects{display:none}.mw-parser-output .mw-authority-control .mw-mf-linked-projects{display:flex;padding:0.5em;border:1px solid #c8ccd1;background-color:#eaecf0;color:#222222}.mw-parser-output .mw-authority-control .mw-mf-linked-projects ul li{margin-bottom:0}Control de autoridadesProyectos Wikimedia']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://es.wikipedia.org/wiki/Pearl_Jam'\n",
    "\n",
    "content = get_wiki_article(url)\n",
    "content = filter_paragraphs(content)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh %E4%B8%AD%E5%AF%86%E6%AD%87%E6%A0%B9%E5%A4%A7%E5%AD%A6\n"
     ]
    }
   ],
   "source": [
    "url = 'https://zh.wikipedia.org/zh-sg/%E4%B8%AD%E5%AF%86%E6%AD%87%E6%A0%B9%E5%A4%A7%E5%AD%A6'\n",
    "matches = re.search(r'https?://(?:www)?(.+)\\.wikipedia\\.org/(?:wiki|.+-.+)/([^&]+)', url)\n",
    "wiki_region = matches[1]\n",
    "page_id = matches[2]\n",
    "\n",
    "print(wiki_region, page_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MKQA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_es_number_unit(raw_unit_name):\n",
    "    es_conversion = {\n",
    "        'Antes de la era vulgar': ['a.C.'],\n",
    "        'Galones': ['galón'],\n",
    "        'Millas por hora': ['mph', 'milla por hora'],\n",
    "        'acre': ['acre'],\n",
    "        'antes del Mediodia': ['AM', 'A.M.'],\n",
    "        'año terrestre': ['año'],\n",
    "        'caballo de potencia metrico': ['caballo de potencia', 'caballo', 'hp', 'cv'],\n",
    "        'centímetro': ['cm', 'centímetro'],\n",
    "        'día': ['día'],\n",
    "        'dólar estadounidense': ['dólar', '$'],\n",
    "        'episodio': ['episodio'],\n",
    "        'escala Fahrenheit': ['grado Fahrenheit', 'Fahrenheit', 'ºF'],\n",
    "        'estaciones del año': ['temporada'],\n",
    "        'grados centigrados': ['grado centigrado', 'grado', 'ºC'],\n",
    "        'gramo': ['gramo', 'gr', 'g'],\n",
    "        'hora': ['hora', 'h'],\n",
    "        'kilometraje': ['kilómetro', 'km'],\n",
    "        'libra avoirdupois': ['libra avoirdupois', 'libra', 'lb'],\n",
    "        'light año terrestre': ['año luz'],\n",
    "        'mes sinódico': ['mes sinódico', 'mes'],\n",
    "        'metros': ['metro', 'm'],\n",
    "        'metros por segundo': ['metro por segundo', 'mps', 'm/s'],\n",
    "        'mililitro': ['mililitro', 'ml'],\n",
    "        'milimetro': ['milímetro', 'mm'],\n",
    "        'milla': ['milla', 'mi'],\n",
    "        'millas cuadradas': ['milla cuadrada'],\n",
    "        'minuto': ['minuto'],\n",
    "        'onza': ['onza'],\n",
    "        'other currency': [],\n",
    "        'other unit': [],\n",
    "        'palabra': ['palabra'],\n",
    "        'pie': ['pie'],\n",
    "        'pies cuadrados': ['pie cuadrado'],\n",
    "        'post meridiem (time)': ['PM', 'P.M.'],\n",
    "        'pulgada': ['pulgada'],\n",
    "        'segundos': ['segundo'],\n",
    "        'septenario': ['septenario'],\n",
    "        'tanto por ciento': ['porcentaje', '%'],\n",
    "    }\n",
    "    \n",
    "    if raw_unit_name not in es_conversion or len(es_conversion[raw_unit_name]) == 0:\n",
    "        return ['']\n",
    "    else:\n",
    "        return [x for x in es_conversion[raw_unit_name]]\n",
    "\n",
    "def parse_nwu_answer_es(raw_answer):\n",
    "    \"\"\"\n",
    "    Parses Spanish answers of type number_with_unit (nwu).\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "\n",
    "    x_interval = re.search(r'^([\\d.]+) ([\\d.]+)(?: (.+))?$', raw_answer)\n",
    "    if x_interval:\n",
    "        unit_value_1 = x_interval[1]\n",
    "        unit_value_2 = x_interval[2]\n",
    "        unit_names = get_es_number_unit(x_interval[3])\n",
    "        if len(unit_names) == 0:\n",
    "            # Skip if not unit name is provided in range of values\n",
    "            pass\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('entre %s y %s %s' % (unit_value_1, unit_value_2, unit_name))\n",
    "                answers.append('desde %s hasta %s %s' % (unit_value_1, unit_value_2, unit_name))\n",
    "    else:\n",
    "        x_single = re.search(r'^([\\d.]+)(?: (.+))$', raw_answer)\n",
    "        if x_single is None:\n",
    "            return []\n",
    "        unit_value = x_single[1]\n",
    "        unit_names = get_es_number_unit(x_single[2])\n",
    "        if len(unit_names) == 0:\n",
    "            answers.append(unit_value)\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('%s %s' % (unit_value, unit_name))\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ja_number_unit(raw_unit_name):\n",
    "    return [raw_unit_name]\n",
    "\n",
    "def parse_nwu_answer_ja(raw_answer):\n",
    "    \"\"\"\n",
    "    Parses Japanese answers of type number_with_unit (nwu).\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "\n",
    "    x_interval = re.search(r'^([\\d.]+) ([\\d.]+)(?: (.+))?$', raw_answer)\n",
    "    if x_interval:\n",
    "        unit_value_1 = x_interval[1]\n",
    "        unit_value_2 = x_interval[2]\n",
    "        unit_names = get_ja_number_unit(x_interval[3])\n",
    "        if len(unit_names) == 0:\n",
    "            # No unit names provided\n",
    "            unit_names = ['']\n",
    "\n",
    "        for unit_name in unit_names:\n",
    "            answers.append('%s%sから%s%sまで' % (unit_value_1, unit_name, unit_value_2, unit_name))\n",
    "            answers.append('%s%sから%s%s' % (unit_value_1, unit_name, unit_value_2, unit_name))\n",
    "            answers.append('%s%s乃至%s%s' % (unit_value_1, unit_name, unit_value_2, unit_name))\n",
    "    else:\n",
    "        x_single = re.search(r'^([\\d.]+)(?: (.+))?$', raw_answer)\n",
    "        if x_single is None:\n",
    "            return []\n",
    "        unit_value = x_single[1]\n",
    "        unit_names = get_ja_number_unit(x_single[2])\n",
    "        if len(unit_names) == 0:\n",
    "            answers.append(unit_value)\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('%s%s' % (unit_value, unit_name))\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ru_number_unit(raw_unit_name):\n",
    "    ru_conversion = {\n",
    "        'Ounce': ['унция'],\n",
    "        'Pound': ['фунт', 'lb'],\n",
    "        'a.m. (time)': ['часов дня', 'утра'],\n",
    "        'bc (date)': ['до н.э.'],\n",
    "        'other currency': [],\n",
    "        'other unit': [],\n",
    "        'p.m. (time)': ['часов вечера', 'вечера'],\n",
    "        'square английский фут': ['квадратный английский фут', 'квадратный фут', 'фут'],\n",
    "        'акр': ['акр'],\n",
    "        'американский доллар': ['американский доллар', 'доллар', '$'],\n",
    "        'английский фут': ['английский фут', 'фут'],\n",
    "        'времена года': ['времена года', 'сезон'],\n",
    "        'градус Фаренгейта': ['градус Фаренгейта', 'Фаренгейта', 'ºF'],\n",
    "        'грамм': ['грамм', 'гр', 'г'],\n",
    "        'дюйм': ['дюйм', 'inch'],\n",
    "        'имперский галлон': ['имперский галлон', 'галлон', 'gallon'],\n",
    "        'квадратная миля': ['квадратная миля', 'миля'],\n",
    "        'километр': ['километр', 'км'],\n",
    "        'лет': ['лет'],\n",
    "        'лошадиная сила': ['лошадиная сила', 'л.с', 'лс'],\n",
    "        'метр': ['метр', 'м'],\n",
    "        'метр в секунду': ['метр в секунду', 'м/с', 'm/s'],\n",
    "        'миллилитр': ['миллилитр', 'мл'],\n",
    "        'миллиметр': ['миллиметр', 'мм'],\n",
    "        'миля': ['миля'],\n",
    "        'миля в час': ['миля в час', 'м/с'],\n",
    "        'минута': ['минута', 'мин', 'м'],\n",
    "        'сантиметр': ['сантиметр', 'см'],\n",
    "        'световой год': ['световой год', 'св. год', 'св. г.'],\n",
    "        'седьмица': ['седьмица', 'седмица', 'неделя'],\n",
    "        'секунда': ['секунда', 'с'],\n",
    "        'синодический лунный месяц': ['синодический лунный месяц', 'лунный месяц'],\n",
    "        'слово': ['слово'],\n",
    "        'сотая доля': ['сотая доля', 'сотая часть', 'сотый'],\n",
    "        'суток': ['суток', 'день'],\n",
    "        'температурная шкала Цельсия': ['градус Цельсия', 'Цельсия', 'ºC'],\n",
    "        'часов': ['час'],\n",
    "        'эпизод': ['эпизод'],\n",
    "    }\n",
    "    \n",
    "    if raw_unit_name not in ru_conversion or len(ru_conversion[raw_unit_name]) == 0:\n",
    "        return ['']\n",
    "    else:\n",
    "        return [x for x in ru_conversion[raw_unit_name]]\n",
    "\n",
    "def parse_nwu_answer_ru(raw_answer):\n",
    "    \"\"\"\n",
    "    Parses Russian answers of type number_with_unit (nwu).\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "\n",
    "    x_interval = re.search(r'^([\\d.]+) ([\\d.]+)(?: (.+))?$', raw_answer)\n",
    "    if x_interval:\n",
    "        unit_value_1 = x_interval[1]\n",
    "        unit_value_2 = x_interval[2]\n",
    "        unit_names = get_es_number_unit(x_interval[3])\n",
    "        if len(unit_names) == 0:\n",
    "            # Skip if not unit name is provided in range of values\n",
    "            pass\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('от %s %s до %s %s' % (unit_value_1, unit_name, unit_value_2, unit_name))\n",
    "                answers.append('от %s до %s %s' % (unit_value_1, unit_value_2, unit_name))\n",
    "    else:\n",
    "        x_single = re.search(r'^([\\d.]+)(?: (.+))$', raw_answer)\n",
    "        if x_single is None:\n",
    "            return []\n",
    "        unit_value = x_single[1]\n",
    "        unit_names = get_es_number_unit(x_single[2])\n",
    "        if len(unit_names) == 0:\n",
    "            answers.append(unit_value)\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('%s %s' % (unit_value, unit_name))\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vi_number_unit(raw_unit_name):\n",
    "    vi_conversion = {\n",
    "        'Sức ngựa': ['Sức ngựa', 'Mã lực', 'HP', 'CV'],\n",
    "        'Tiếng đồng hồ': ['Tiếng đồng hồ', 'Giờ'],\n",
    "        'Tập chương trình': ['Tập chương trình'],\n",
    "        'ante meridiem': ['A.M.', 'AM'],\n",
    "        'bc (date)': ['bc'],\n",
    "        'chữ': ['chữ'],\n",
    "        'dặm Anh': ['dặm Anh', 'dặm'],\n",
    "        'dặm vuông Anh': ['dặm vuông Anh', 'dậm vuông Anh' 'dặm vuông'],\n",
    "        'foot': ['foot', 'chân'],\n",
    "        'foot vuông': ['foot vuông', 'square foot'],\n",
    "        'ga-lông': ['ga-lông', 'galông', 'gallon'],\n",
    "        'gam': ['gờ ram', 'cờ ram', 'gam', 'gram', 'g'],\n",
    "        'giây': ['giây', 's'],\n",
    "        'inch': ['inch', 'in'],\n",
    "        'ki-lô-mét': ['ki-lô-mét', 'kilômét', 'km'],\n",
    "        'miles per Tiếng đồng hồ': ['dặm một giờ', 'mph'],\n",
    "        'mililít': ['mililít', 'ml'],\n",
    "        'milimét': ['milimét', 'mm'],\n",
    "        'mét': ['mét', 'm'],\n",
    "        'mét trên giây': ['mét trên giây', 'm/s'],\n",
    "        'mùa': ['mùa', 'phần'],\n",
    "        'mẫu vuông': ['mẫu vuông', 'mẫu', 'acre'],\n",
    "        'ngày': ['ngày'],\n",
    "        'năm': ['năm'],\n",
    "        'năm ánh sáng': ['năm ánh sáng'],\n",
    "        'other currency': [],\n",
    "        'other unit': [],\n",
    "        'ounce avoirdupois quốc tế': ['ounce', 'oz'],\n",
    "        'phút': ['phút', 'm', 'ph'],\n",
    "        'phần trăm': ['phần trăm', '%'],\n",
    "        'post meridiem (time)': ['P.M.', 'PM'],\n",
    "        'pound': ['pound', 'cân Anh', 'pao', 'lb'],\n",
    "        'tháng': ['tháng'],\n",
    "        'tuần': ['tuần'],\n",
    "        'xentimét': ['xentimét', 'cm'],\n",
    "        'đô la Hoa Kì': ['đô la Hoa Kì', 'đô la Hoa Kỳ', 'đô la Mỹ', 'Mỹ kim', '$'],\n",
    "        'độ Fahrenheit': ['độ Fahrenheit', 'độ F', '°F'],\n",
    "        'độ bách phân': ['độ Celsius', 'độ C', '°C'],\n",
    "    }\n",
    "    \n",
    "    if raw_unit_name not in vi_conversion or len(vi_conversion[raw_unit_name]) == 0:\n",
    "        return ['']\n",
    "    else:\n",
    "        return [x for x in vi_conversion[raw_unit_name]]\n",
    "\n",
    "def parse_nwu_answer_vi(raw_answer):\n",
    "    \"\"\"\n",
    "    Parses Vietnamese answers of type number_with_unit (nwu).\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "\n",
    "    x_interval = re.search(r'^([\\d.]+) ([\\d.]+)(?: (.+))?$', raw_answer)\n",
    "    if x_interval:\n",
    "        unit_value_1 = x_interval[1]\n",
    "        unit_value_2 = x_interval[2]\n",
    "        unit_names = get_es_number_unit(x_interval[3])\n",
    "        if len(unit_names) == 0:\n",
    "            # Skip if not unit name is provided in range of values\n",
    "            pass\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('từ %s đến %s %s' % (unit_value_1, unit_value_2, unit_name))\n",
    "                answers.append('từ %s %s đến %s %s' % (unit_value_1, unit_name, unit_value_2, unit_name))\n",
    "    else:\n",
    "        x_single = re.search(r'^([\\d.]+)(?: (.+))$', raw_answer)\n",
    "        if x_single is None:\n",
    "            return []\n",
    "        unit_value = x_single[1]\n",
    "        unit_names = get_es_number_unit(x_single[2])\n",
    "        if len(unit_names) == 0:\n",
    "            answers.append(unit_value)\n",
    "        else:\n",
    "            for unit_name in unit_names:\n",
    "                answers.append('%s %s' % (unit_value, unit_name))\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_answer_es(raw_answer):\n",
    "    date_parts = re.search('^([\\d.]+)-([\\d.]+)-([\\d.]+)$', raw_answer)\n",
    "    if date_parts is None:\n",
    "        # No ISO date format\n",
    "        return [raw_answer]\n",
    "    \n",
    "    month_conversion = ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio',\n",
    "                        'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre']\n",
    "    \n",
    "    year_number = date_parts[1]\n",
    "    month_number = date_parts[2]\n",
    "    month_str = month_conversion[str_to_num(date_parts[2]) - 1]\n",
    "    day_number = date_parts[3]\n",
    "    \n",
    "    return [\n",
    "        '%s-%s-%s' % (year_number, month_number, day_number),\n",
    "        '%s-%s-%s' % (day_number, month_number, year_number),\n",
    "        '%s-%s-%s' % (month_number, day_number, year_number),\n",
    "        '%s/%s/%s' % (month_number, day_number, year_number),\n",
    "        '%s de %s del %s' % (day_number, month_number, year_number),\n",
    "        '%s de %s, %s' % (day_number, month_number, year_number),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_answer_ja(raw_answer):\n",
    "    date_parts = re.search('^([\\d.]+)-([\\d.]+)-([\\d.]+)$', raw_answer)\n",
    "    if date_parts is None:\n",
    "        # No ISO date format\n",
    "        return [raw_answer]\n",
    "    \n",
    "    number_conversion = ['一', '二', '三', '四', '五', '六', '七', '八', '九', '十',\n",
    "                         '十一', '十二', '十三', '十四', '十五', '十六', '十七', '十八', '十九', '二十',\n",
    "                         '二十一', '二十二', '二十三', '二十四', '二十五', '二十六', '二十七', '二十八', '二十九', '三十',\n",
    "                         '三十一']\n",
    "    \n",
    "    year_number = date_parts[1]\n",
    "    month_number = date_parts[2]\n",
    "    day_number = date_parts[3]\n",
    "    \n",
    "    all_dates = [\n",
    "        '%s-%s-%s' % (year_number, month_number, day_number),\n",
    "        '%s-%s-%s' % (day_number, month_number, year_number),\n",
    "        '%s/%s/%s' % (year_number, month_number, day_number),\n",
    "        '%s/%s/%s' % (day_number, month_number, year_number),\n",
    "    ]\n",
    "    \n",
    "    kanji_date = '%s年 %s月 %s日' % (year_number, month_number, day_number)\n",
    "    all_dates = [kanji_date] + all_dates\n",
    "    \n",
    "    month_str = number_conversion[str_to_num(date_parts[2]) - 1]\n",
    "    day_str = number_conversion[str_to_num(date_parts[3]) - 1]\n",
    "    kanji_date = '%s月 %s日' % (month_str, day_str)\n",
    "    all_dates = [kanji_date] + all_dates\n",
    "    \n",
    "    return all_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_answer_ru(raw_answer):\n",
    "    date_parts = re.search('^([\\d.]+)-([\\d.]+)-([\\d.]+)$', raw_answer)\n",
    "    if date_parts is None:\n",
    "        # No ISO date format\n",
    "        return [raw_answer]\n",
    "    \n",
    "    month_conversion = ['январь', 'февраль', 'март', 'апрель', 'май', 'июнь', 'июль',\n",
    "                        'август', 'сентябрь', 'октябрь', 'ноябрь', 'декабрь']\n",
    "    \n",
    "    year_number = date_parts[1]\n",
    "    month_number = date_parts[2]\n",
    "    month_str = month_conversion[str_to_num(date_parts[2]) - 1]\n",
    "    day_number = date_parts[3]\n",
    "    \n",
    "    return [\n",
    "        '%s-%s-%s' % (day_number, month_number, year_number),\n",
    "        '%s.%s.%s' % (day_number, month_number, year_number),\n",
    "        '%s/%s/%s' % (day_number, month_number, year_number),\n",
    "        '%s %s %s г.' % (day_number, month_str, year_number),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_answer_vi(raw_answer):\n",
    "    date_parts = re.search('^([\\d.]+)-([\\d.]+)-([\\d.]+)$', raw_answer)\n",
    "    if date_parts is None:\n",
    "        # No ISO date format\n",
    "        return [raw_answer]\n",
    "    \n",
    "    month_conversion = ['giêng', 'hai', 'ba', 'bốn', 'năm', 'sáu',\n",
    "                        'bảy', 'tám', 'chín', 'mười', 'mười một', 'mười hai']\n",
    "    \n",
    "    year_number = date_parts[1]\n",
    "    month_number = date_parts[2]\n",
    "    month_str = month_conversion[str_to_num(date_parts[2]) - 1]\n",
    "    day_number = date_parts[3]\n",
    "    \n",
    "    return [\n",
    "        '%s tháng %s %s' % (day_number, month_str, year_number),\n",
    "        '%s tháng %s %s' % (day_number, month_number, year_number),\n",
    "        '%s-%s-%s' % (year_number, month_number, day_number),\n",
    "        '%s-%s-%s' % (day_number, month_number, year_number),\n",
    "        '%s/%s/%s' % (day_number, month_number, year_number),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_answer(type, main_answer, aliases, region_code=REGION_CODE):\n",
    "    \"\"\"\n",
    "    Parses MKQA Answers.\n",
    "    \"\"\"\n",
    "    \n",
    "    if REGION_CODE == 'es':\n",
    "        parse_functions = {\n",
    "            'number_with_unit': parse_nwu_answer_es,\n",
    "            'date': parse_date_answer_es,\n",
    "        }\n",
    "    elif REGION_CODE == 'ja':\n",
    "        parse_functions = {\n",
    "            'number_with_unit': parse_nwu_answer_ja,\n",
    "            'date': parse_date_answer_ja,\n",
    "        }\n",
    "    elif REGION_CODE == 'ru':\n",
    "        parse_functions = {\n",
    "            'number_with_unit': parse_nwu_answer_ru,\n",
    "            'date': parse_date_answer_ru,\n",
    "        }\n",
    "    elif REGION_CODE == 'vi':\n",
    "        parse_functions = {\n",
    "            'number_with_unit': parse_nwu_answer_vi,\n",
    "            'date': parse_date_answer_vi,\n",
    "        }\n",
    "    else:\n",
    "        raise Exception('Unknown region code: %s' % REGION_CODE)\n",
    "    \n",
    "    parsed_answers = []\n",
    "    if type == 'number_with_unit':\n",
    "        # Example: 16.0 año terrestre\n",
    "        parsed_answers += parse_functions[type](main_answer)\n",
    "        for alias in aliases:\n",
    "            parsed_answers += parse_functions[type](alias)\n",
    "    #elif type == 'number':\n",
    "    #    # Example: 104.0\n",
    "    #    parsed_answers.append(main_answer)\n",
    "    #    for alias in aliases:\n",
    "    #        parsed_answers.append(alias)\n",
    "    elif type == 'date':\n",
    "        # Example: 2001-08-29\n",
    "        parsed_answers += parse_functions[type](main_answer)\n",
    "    elif type == 'entity':\n",
    "        # Example: Pokémon Ranger: Sombras de Almia\n",
    "        parsed_answers.append(main_answer.strip())\n",
    "        for alias in aliases:\n",
    "            parsed_answers.append(alias.strip())\n",
    "    elif type == 'short_phrase':\n",
    "        # Example: rosemary almond\n",
    "        parsed_answers.append(main_answer.strip())\n",
    "        for alias in aliases:\n",
    "            parsed_answers.append(alias.strip())\n",
    "    else:\n",
    "        # Ignored types: unanswerable, long_answer, binary\n",
    "        pass\n",
    "    \n",
    "    # Filter low-quality answers (e.g. only numbers)\n",
    "    parsed_answers = [x for x in parsed_answers if not re.search(r'^[\\d.]+$', x)]\n",
    "    parsed_answers = [x for x in parsed_answers if x != '']\n",
    "    \n",
    "    return parsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answers(context, context_tokens, answers, answers_tokens, min_bleu, min_answer_length=3, max_answer_length=30):\n",
    "    found_answers = []\n",
    "    \n",
    "    context_lemmas = [token[1] for token in context_tokens]\n",
    "    context_offsets = [token[2] for token in context_tokens]\n",
    "    \n",
    "    for answer_tokens in answers_tokens:\n",
    "        answer_lemmas = [token[1] for token in answer_tokens]\n",
    "        \n",
    "        window_size = len(answer_tokens)\n",
    "        i = 0\n",
    "        while i < len(context_tokens) - window_size:\n",
    "            score = bleu_score(answer_lemmas, context_lemmas[i:i+window_size])\n",
    "            span_start = context_offsets[i][0]\n",
    "            span_end = context_offsets[i+window_size-1][1]\n",
    "            context_answer = context[span_start:span_end]\n",
    "            if (score >= min_bleu and len(context_answer) <= max_answer_length and\n",
    "                len(context_answer) >= min_answer_length and context_answer.strip() != ''):\n",
    "                found_answers.append({\n",
    "                    'answer_start': span_start,\n",
    "                    'answer_end': span_end,\n",
    "                    'text': context[span_start:span_end],\n",
    "                })\n",
    "                i += window_size # Skips answer position\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    return found_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_piece_tokenizer(artifacts_path='../artifacts/', lm_name='bert-base-multilingual-cased', lowercase=False):\n",
    "    save_path = '%s%s/' % (artifacts_path, lm_name)\n",
    "    tokenizer = BertTokenizerFast('%svocab.txt' % save_path, do_lower_case=lowercase)\n",
    "    return lambda text : [text[start:end] \\\n",
    "                          for (start, end) in tokenizer(text, return_offsets_mapping=True,\n",
    "                                                        return_special_tokens_mask=False)['offset_mapping'][1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokenizer(dictionary_name=None, region_code=REGION_CODE):\n",
    "    if region_code == 'vi':\n",
    "        nlp = Vietnamese()\n",
    "    else:\n",
    "        nlp = spacy.load(dictionary_name)\n",
    "    return lambda text : [(token.text, (token.lemma_ if token.lemma_ != '' else token.text.lower()), [token.idx, token.idx + len(token.text)]) for token in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(reference, hypothesis):\n",
    "    matches = [int(x == y) for x, y in zip(reference, hypothesis)]\n",
    "    return sum(matches) / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['esta', 'es', 'prueba','1']\n",
    "b = ['esta', 'es', 'prueba','2']\n",
    "\n",
    "bleu_score(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¡', 'Ho', 'la', 'mundo', '!', '¡', 'Adi', 'ós', 'mundo', '!']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '¡Hola mundo! ¡Adiós mundo!'\n",
    "\n",
    "tokenizer = get_piece_tokenizer()\n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('¡', '¡', [0, 1]),\n",
       " ('Hola', 'hola', [1, 5]),\n",
       " ('mundo', 'mundo', [6, 11]),\n",
       " ('!', '!', [11, 12]),\n",
       " ('¡', '¡', [13, 14]),\n",
       " ('Adiós', 'adiós', [14, 19]),\n",
       " ('mundo', 'mundo', [20, 25]),\n",
       " ('!', '!', [25, 26])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '¡Hola mundo! ¡Adiós mundo!'\n",
    "\n",
    "tokenizer = get_word_tokenizer(SPACY_DICT)\n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemPicker():\n",
    "    def __init__(self, dataset, timeout=60, sleep_interval=1):\n",
    "        self._n_items = len(dataset)\n",
    "        self._dataset = dataset\n",
    "        self._idx = 0\n",
    "        self._timeout = timeout\n",
    "        self._sleep_interval = sleep_interval\n",
    "        self._locked = False\n",
    "    \n",
    "    def pick(self):\n",
    "        self.lock()\n",
    "        if self._idx >= self._n_items:\n",
    "            item = None\n",
    "        else:\n",
    "            item = self._dataset.pop(0)\n",
    "            self._idx += 1\n",
    "        self.unlock()\n",
    "        return item\n",
    "\n",
    "    def lock(self):\n",
    "        start_time = time.time()\n",
    "        while self._locked:\n",
    "            end_time = time.time()\n",
    "            if end_time - start_time >= self._timeout:\n",
    "                raise Exception('Cannot pick an item (timeout)')\n",
    "            sleep(self._sleep_interval)\n",
    "        self._locked = True\n",
    "    \n",
    "    def unlock(self):\n",
    "        self._locked = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_squad_items(squad_items, top_items):\n",
    "    squad_items = sorted(squad_items, key=lambda kv: kv['score'], reverse=True)\n",
    "    return squad_items[:top_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_entities(text, default_score=5.):\n",
    "    all_matches = []\n",
    "    matches = re.findall(r'\"(.+?)\"', text)\n",
    "    if len(matches) > 0:\n",
    "        all_matches += [x.strip() for x in matches]\n",
    "    matches = re.findall(r'\\'(.+?)\\'', text)\n",
    "    if len(matches) > 0:\n",
    "        all_matches += [x.strip() for x in matches]\n",
    "    matches = re.findall(r'((?:(?:[A-Z][A-Za-z]+|de)\\s?)+)', text)\n",
    "    if len(matches) > 0:\n",
    "        all_matches += [x.strip() for x in matches]\n",
    "    \n",
    "    # Format static entities\n",
    "    static_entities = []\n",
    "    for x in all_matches:\n",
    "        static_entities.append({\n",
    "            'entity_text': x,\n",
    "            'entity_score': default_score,\n",
    "            'is_mandatory': True,\n",
    "        })\n",
    "    \n",
    "    return static_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_entities(context, entities, n=1):\n",
    "    if entities is None or len(entities) == 0:\n",
    "        return True, 0.\n",
    "    \n",
    "    counter = 0\n",
    "    max_score = 0.\n",
    "    current_score = 0.\n",
    "    for entity in entities:\n",
    "        max_score = entity['entity_score']\n",
    "        if context.find(entity['entity_text']) != -1:\n",
    "            # Found entity\n",
    "            counter += 1\n",
    "            current_score += entity['entity_score']\n",
    "        elif 'is_mandatory' in entity and entity['is_mandatory']:\n",
    "            # Mandatory entitiy not found\n",
    "            return False, 0.\n",
    "    \n",
    "    return (counter >= n), (current_score / max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_tokens(context, tokens, token_score=1.):\n",
    "    if tokens is None or len(tokens) == 0:\n",
    "        raise Exception('No tokens provided for context: %s' % context)\n",
    "    \n",
    "    max_score = 0\n",
    "    current_score = 0.\n",
    "    for token in tokens:\n",
    "        if token in list(STOPWORDS):\n",
    "            continue\n",
    "        max_score += token_score\n",
    "        if context.find(token) != -1:\n",
    "            # Found token\n",
    "            current_score += token_score\n",
    "    \n",
    "    return current_score / max_score if max_score > 0 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_squad_item(idx, question, answers, answer_types, piece_tokenizers,\n",
    "                    word_tokenizer, query_top_results, max_threads=3,\n",
    "                    min_bleu=0.8, max_pieces_length=512, max_chars_length=1500):\n",
    "    if len(piece_tokenizers) != max_threads:\n",
    "        raise Exception('Need more tokenizers (expected: %d).' % max_threads)\n",
    "\n",
    "    question_pieces = piece_tokenizers[0](question)\n",
    "    question_tokens = word_tokenizer(question)\n",
    "    \n",
    "    answers_tokens = [word_tokenizer(answer) for answer in answers]\n",
    "    \n",
    "    # Sort answers by length\n",
    "    a_zip = sorted(zip(answers, answer_types, answers_tokens), key=lambda x: len(x[0]), reverse=True)\n",
    "    answers, answer_types, answers_tokens = list(zip(*a_zip))\n",
    "    \n",
    "    # Get top results of Google\n",
    "    url_items = google_search(question, top_results=query_top_results)\n",
    "    static_entities = get_static_entities(question)\n",
    "    \n",
    "    # Get page content of each ID\n",
    "    squad_items = []\n",
    "    end_status = []\n",
    "    all_threads = []\n",
    "\n",
    "    n_threads = 0\n",
    "    url_picker = ItemPicker(url_items)\n",
    "    n_threads = min([max_threads, len(url_items)])\n",
    "    \n",
    "    for i in range(n_threads):\n",
    "        x = threading.Thread(\n",
    "            target=find_squad_item_in_url,\n",
    "            args=(end_status, squad_items, idx, url_picker, piece_tokenizers[i], word_tokenizer,\n",
    "                  question, question_pieces, question_tokens, answers, answer_types, answers_tokens,\n",
    "                  static_entities, min_bleu, max_pieces_length, max_chars_length))\n",
    "        x.start()\n",
    "        all_threads.append(x)\n",
    "        sleep(1)\n",
    "    \n",
    "    # Wait for threads\n",
    "    for x in all_threads:\n",
    "        x.join()\n",
    "    \n",
    "    if sum(end_status) != len(all_threads):\n",
    "        raise Exception('Some thread failed!')\n",
    "    \n",
    "    return squad_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_squad_item_in_url(end_status, squad_items, idx, url_picker, piece_tokenizer, word_tokenizer,\n",
    "                           question, question_pieces, question_tokens, answers, answer_types, answers_tokens,\n",
    "                           static_entities, min_bleu, max_pieces_length, max_chars_length):\n",
    "    url_item = url_picker.pick()\n",
    "    if url_item is None:\n",
    "        end_status.append(1)\n",
    "        return\n",
    "    \n",
    "    page_url = url_item['url']\n",
    "    page_title = url_item['title']\n",
    "    \n",
    "    try:\n",
    "        wiki_article = get_wiki_article(page_url)\n",
    "    except Exception as e:\n",
    "        print(page_title, '|', page_url)\n",
    "        raise e\n",
    "    try:\n",
    "        paragraphs = filter_paragraphs(wiki_article)\n",
    "    except Exception as e:\n",
    "        print(page_title, '|', page_url)\n",
    "        print(wiki_article)\n",
    "        raise e\n",
    "\n",
    "    for paragraph_i, paragraph in enumerate(paragraphs):\n",
    "        try:\n",
    "            paragraph_pieces = piece_tokenizer(paragraph)\n",
    "            paragraph_tokens = word_tokenizer(paragraph)\n",
    "        except:\n",
    "            # Something bad is in the paragraph\n",
    "            continue\n",
    "\n",
    "        pieces_length = len(paragraph_pieces) + len(question_pieces) # Context + question\n",
    "        chars_length = sum(len(piece) for piece in paragraph_pieces) # Only context\n",
    "\n",
    "        if pieces_length <= (max_pieces_length - 3) and chars_length <= max_chars_length:\n",
    "            p_has_entities, entities_score = has_entities(paragraph, static_entities, n=1)\n",
    "            if p_has_entities:\n",
    "                found_answers = find_answers(paragraph, paragraph_tokens, answers, answers_tokens, min_bleu=min_bleu)\n",
    "                tokens_score = has_tokens(paragraph, [token[1] for token in question_tokens])\n",
    "                if len(found_answers) > 0:\n",
    "                    squad_score = entities_score + tokens_score + max([len(x['text']) for x in found_answers])\n",
    "                    squad_item = {\n",
    "                        'score': squad_score,\n",
    "                        'title': page_title,\n",
    "                        'paragraphs': [{\n",
    "                            'context': paragraph,\n",
    "                            'qas': [{\n",
    "                                'id': '%s_%d' % (idx, paragraph_i),\n",
    "                                'question': question,\n",
    "                                'answers': [],\n",
    "                            }],\n",
    "                        }],\n",
    "                    }\n",
    "                    for found_answer in found_answers:\n",
    "                        squad_item['paragraphs'][0]['qas'][0]['answers'].append({\n",
    "                            'answer_start': found_answer['answer_start'],\n",
    "                            'text': found_answer['text'],\n",
    "                        })\n",
    "                    squad_items.append(squad_item)\n",
    "    \n",
    "    end_status.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manager of config.json with a simple lock file\n",
    "class ConfigManager:\n",
    "    def __init__(self, save_path, timeout=60, sleep_interval=1):\n",
    "        self._save_path = save_path\n",
    "        self._timeout = timeout\n",
    "        self._sleep_interval = sleep_interval\n",
    "        self._locked = False\n",
    "    \n",
    "    def read(self):\n",
    "        self.lock()\n",
    "        config_file = os.path.join(self._save_path, 'config.json')\n",
    "        if os.path.exists(config_file):\n",
    "            with open(config_file, 'r') as fp:\n",
    "                config = json.load(fp)\n",
    "        else:\n",
    "            with open(config_file, 'w') as fp:\n",
    "                config = {'skipped': [], 'found': []}\n",
    "                json.dump(config, fp)\n",
    "        self.unlock()\n",
    "        return config\n",
    "\n",
    "    def save(self, config_data):\n",
    "        self.lock()\n",
    "        config_file = os.path.join(self._save_path, 'config.json')\n",
    "        with open(config_file, 'w') as fp:\n",
    "            json.dump(config_data, fp)\n",
    "        self.unlock()\n",
    "\n",
    "    def lock(self):\n",
    "        start_time = time.time()\n",
    "        while self._locked:\n",
    "            end_time = time.time()\n",
    "            if end_time - start_time >= self._timeout:\n",
    "                raise Exception('Cannot lock config file (timeout)')\n",
    "            sleep(self._sleep_interval)\n",
    "        self._locked = True\n",
    "    \n",
    "    def unlock(self):\n",
    "        self._locked = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggerThread(threading.Thread):\n",
    "    def __init__(self, n_items, config_manager, sleep_interval=5):\n",
    "        super().__init__()\n",
    "        self._n_items = n_items\n",
    "        self._config_manager = config_manager\n",
    "        self._sleep_interval = sleep_interval\n",
    "        self._kill = threading.Event()\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            config = config_manager.read()\n",
    "            n_skipped = len(config['skipped'])\n",
    "            n_found = len(config['found'])\n",
    "            n_processed = n_skipped + n_found\n",
    "            print('- Processed: %d / %d | Found: %d' % (n_processed, self._n_items, n_found), ' '*20, end='\\r')\n",
    "            \n",
    "            is_killed = self._kill.wait(self._sleep_interval)\n",
    "            if is_killed:\n",
    "                break\n",
    "\n",
    "    def kill(self):\n",
    "        self._kill.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(end_status, save_path, item_picker, config_manager, max_threads=7,\n",
    "         region_code=REGION_CODE, spacy_dict=SPACY_DICT, max_aliases=5, query_top_results=7):\n",
    "    # Load initial config\n",
    "    config = config_manager.read()\n",
    "\n",
    "    # Need one tokenizer as many query_top_results (since we need one per thread)\n",
    "    piece_tokenizers = [get_piece_tokenizer() for _ in range(max_threads)]\n",
    "    word_tokenizer = get_word_tokenizer(SPACY_DICT)\n",
    "    \n",
    "    # Create subdirs\n",
    "    top_items = [1, 2, 3, 5]\n",
    "    for k in top_items:\n",
    "        k_save_path = os.path.join(save_path, 'top_%d' % k)\n",
    "        os.makedirs(k_save_path, exist_ok=True)\n",
    "    \n",
    "    while True:\n",
    "        item = item_picker.pick()\n",
    "        if item is None:\n",
    "            break\n",
    "        \n",
    "        idx = 'mkqa_' + str(item['example_id'])\n",
    "        query = item['queries'][region_code]\n",
    "        \n",
    "        # Skip if already parsed\n",
    "        file_exists = os.path.exists(os.path.join(save_path, 'top_1', '%s.json' % idx))\n",
    "        if item['example_id'] in config['found'] or item['example_id'] in config['skipped'] or file_exists:\n",
    "            continue\n",
    "        \n",
    "        parsed_answers = []\n",
    "        answer_types = []\n",
    "        for raw_answer_data in item['answers'][region_code]:\n",
    "            main_answer = raw_answer_data['text']\n",
    "            aliases = raw_answer_data['aliases'][:max_aliases] if 'aliases' in raw_answer_data else []\n",
    "            \n",
    "            iter_parsed_answers = parse_raw_answer(raw_answer_data['type'], main_answer,\n",
    "                                                   aliases, region_code=REGION_CODE)\n",
    "            \n",
    "            for iter_parsed_answer in iter_parsed_answers:\n",
    "                if iter_parsed_answer not in parsed_answers:\n",
    "                    parsed_answers.append(iter_parsed_answer)\n",
    "                    answer_types.append(raw_answer_data['type'])\n",
    "        \n",
    "        if len(parsed_answers) == 0:\n",
    "            # No answers for this query\n",
    "            config = config_manager.read()\n",
    "            config['skipped'].append(item['example_id'])\n",
    "            config_manager.save(config)\n",
    "            continue\n",
    "        \n",
    "        squad_items = find_squad_item(\n",
    "                idx, query, parsed_answers, answer_types, piece_tokenizers, word_tokenizer,\n",
    "                max_threads=max_threads, query_top_results=query_top_results)\n",
    "        \n",
    "        if len(squad_items) == 0:\n",
    "            config = config_manager.read()\n",
    "            config['skipped'].append(item['example_id'])\n",
    "            config_manager.save(config)\n",
    "            continue\n",
    "        \n",
    "        for k in top_items:\n",
    "            output_file = os.path.join(save_path, 'top_%d' % k, '%s.json' % idx)\n",
    "            with open(output_file, 'w', encoding='utf8') as fp:\n",
    "                squad_dataset = {'data': get_best_squad_items(squad_items, top_items=k)}\n",
    "                json.dump(squad_dataset, fp, ensure_ascii=False)\n",
    "        \n",
    "        config = config_manager.read()\n",
    "        config['found'].append(item['example_id'])\n",
    "        config_manager.save(config)\n",
    "        \n",
    "        # Save memory\n",
    "        del squad_items\n",
    "        del squad_dataset\n",
    "    \n",
    "    end_status.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config manager...\n",
      "Loading item picker...\n",
      "Loading logger thread...\n",
      "- Processed: 9999 / 10000 | Found: 1354                     \n",
      "Killing logger thread...\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "max_errors = 2\n",
    "n_errors = 0\n",
    "n_threads = 12\n",
    "n_sub_threads = 1\n",
    "\n",
    "#######\n",
    "\n",
    "save_path = os.path.join(OUTPUT_PATH, REGION_CODE)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "print('Loading config manager...')\n",
    "config_manager = ConfigManager(save_path)\n",
    "config_manager.read() # Just to create the initial config file if not exists\n",
    "\n",
    "print('Loading item picker...')\n",
    "item_picker = ItemPicker(mkqa_dataset)\n",
    "\n",
    "print('Loading logger thread...')\n",
    "n_items = len(mkqa_dataset)\n",
    "logger_thread = LoggerThread(n_items, config_manager)\n",
    "logger_thread.start()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        all_main_threads = []\n",
    "        end_status = []\n",
    "        \n",
    "        # Start first thread as warm-up\n",
    "        x = threading.Thread(\n",
    "            target=main,\n",
    "            args=(end_status, save_path, item_picker, config_manager, n_sub_threads))\n",
    "        x.start()\n",
    "        all_main_threads.append(x)\n",
    "        sleep(5)\n",
    "        \n",
    "        # Start rest of threads\n",
    "        for _ in range(n_threads - 1):\n",
    "            x = threading.Thread(\n",
    "                target=main,\n",
    "                args=(end_status, save_path, item_picker, config_manager, n_sub_threads))\n",
    "            x.start()\n",
    "            all_main_threads.append(x)\n",
    "            sleep(1)\n",
    "\n",
    "        for x in all_main_threads:\n",
    "            x.join()\n",
    "        \n",
    "        print()\n",
    "        logger_thread.kill()\n",
    "        print('Killing logger thread...')\n",
    "        logger_thread.join()\n",
    "\n",
    "        if sum(end_status) != len(all_main_threads):\n",
    "            raise Exception('Some thread failed!')\n",
    "        break\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        n_errors += 1\n",
    "        if n_errors >= max_errors:\n",
    "            raise e\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print('-' * 10)\n",
    "        print(e)\n",
    "        raise e\n",
    "        sleep(5)\n",
    "\n",
    "print()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
